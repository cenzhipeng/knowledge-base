---
id: future并发
title: 本文内容
sidebar_label: future并发
---



## 用法

```
def download_many(cc_list):
    workers = min(MAX_WORKERS, len(cc_list))
    with futures.ThreadPoolExecutor(workers) as executor:
        res = executor.map(download_one, sorted(cc_list))
    return len(list(res))
```

- `futures.ThreadPoolExecutor(num)` 开启线程池
- `executor.map(download_one, sorted(cc_list))` 线程池里提交任务（这里是提交了多个任务）
- 也可以使用 `executor.submit()` 提交一个任务，返回一个 future
- 其实用法跟各个语言的 future 都很像

### 代码

```
# version1
# def download_many(cc_list):
#     workers = min(MAX_WORKERS, len(cc_list))
#     with futures.ThreadPoolExecutor(workers) as executor:
#         res = executor.map(download_one, sorted(cc_list))
#     return len(list(res))


# version2
def download_many(cc_list):
    workers = min(MAX_WORKERS, len(cc_list))
    with futures.ThreadPoolExecutor(workers) as executor:
        future_list = []
        for cc in sorted(cc_list):
            future = executor.submit(download_one, cc)
            future_list.append(future)
        # 等待所有 future 完成（这里有几种策略，可以添加 return_when 参数，默认是等待所有）
        done, _ = futures.wait(future_list)  # 第二个参数表示未完成的 future

    return len(list(done))

```

### 说明

#### done 方法

每个 future 都有 done 方法，它立即返回一个布尔值，表示 future 是否完成了（完成、取消、异常了等等）

### add_done_callback 方法

添加一个回调，future 结束后立即调用

#### result 方法

获取 future 的结果。

- 如果 future 还在运行，将会阻塞当前线程直到获取结果
- 如果设置超时时间还没有结果，抛出 TimeoutError
- 如果 future 出错了，原样抛出 future 里的异常

#### futures.as_completed 方法

这个方法接收 future 列表，返回一个迭代器。

这个迭代器的每一项都是一个已完成的 future，future 的顺序并没有保证，哪个 future 完成了就会被返回（不会一直阻塞在时间最长的 future 上，便于处理进度等信息）

其实跟 wait 方法很相似



## GIL

参考：[GIL讲解](http://c.biancheng.net/view/5537.html)

global interpreter lock：全局解释锁

简单说就是：CPython 解释器本身并不是线程安全的，它有全局解释器锁，一次只允许一个线程执行 Python 字节码。

所以就导致了 python 的多线程很傻逼，实际上只能利用一个 CPU 核心。

GIL 的功能是：在 CPython 解释器中执行的每一个 Python 线程，都会先锁住自己，以阻止别的线程执行。

当然，CPython 不可能容忍一个线程一直独占解释器，它会轮流执行 Python 线程。这样一来，用户看到的就是伪并行，即 Python 线程在交替执行，来模拟真正并行的线程。

其实就是常规的时间分片来执行各个线程。

### IO

当然 python 也不会特别傻逼。

当一个线程执行阻塞型的 IO 操作时，它会释放掉自己的 GIL 锁，以便其他线程去执行。

所以对于 IO 密集型的程序来说，GIL 不算是个大事儿（跟单线程的 node 其实挺像的）



## 线程和进程的理解

虽然不一定准确，但是我是这样理解的：

- 进程是系统权限的集合
- 线程是 CPU 调度的最小单位

一个进程ID表示了这个进程可以访问哪些内存空间、文件描述符等资源。

一个线程ID表示了CPU调度的一个实体，也就是说，当我们说 A 进程在执行时，其实是在说：CPU 正在 A 进程的某个线程 A.a 上执行。

很可能过了一会儿 CPU 就又调度起了 A 进程的另一个线程 A.b，此时两个线程同时在执行。

操作系统层面的调度说：该轮到 A 进程执行了。于是就将 CPU 资源分配给了 A 进程的某个线程

由于 python 有 GIL，因此会发生以下情况：

- 当我们只允许一个主线程时，它一直持有 GIL
- 当我们在主线程 a 里启动另一个线程 b
  - a 和 b 在 操作系统层面，都被 CPU 调度了
  - a 持有 GIL 锁可以继续执行，b 没有 GIL 锁，卡住了（忙等待或者主动让出 CPU 资源）
  - 如果此时 a 失去了 CPU 资源，而 b 还在被 CPU 调度，由于 b 还是没有 GIL 锁，所以还是无法执行，必须继续等待 a 线程执行，直到解释器将 a 的 GIL 锁释放

也就是如此，python 中永远只有一个线程在执行



## 多进程

IO 密集型的应用，一个线程不是什么大问题，但是 CPU 密集型的应用，如果只有一个线程来执行，那肯定是受不了的，所以 python 提供了多进程的方案，也就是说同时启动多个 python 进程

concurrent.futures 模块除了使用 `futures.ThreadPoolExecutor` 开启线程池之外，其实也是可以使用 `futures.ProcessPoolExecutor` 来开启进程池的。

它可以将工作分配给多个 python 进程来处理，从而避开了一部分 GIL 的限制

如上代码可以很简单的改成

```
def download_many(cc_list):
    workers = min(MAX_WORKERS, len(cc_list))
    with futures.ProcessPoolExecutor() as executor:
        res = executor.map(download_one, sorted(cc_list))
    return len(list(res))
```

`ThreadPool Executor.__init__` 方 法 需 要 max_workers 参 数， 指 定 线 程 池 中 线 程 的 数 量。 在 ProcessPoolExecutor 类中，那个参数是可选的，而且大多数情况下不使用——默认值是 os.cpu_count() 函数返回的 CPU 数量

