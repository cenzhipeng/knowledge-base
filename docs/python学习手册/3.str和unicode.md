---
id: str和unicode
title: 本文内容
sidebar_label: str和unicode
---



## 概述

本文主要针对 python2



## 什么叫编码

- 把人类能看懂的字符，写成计算机能看懂的内容（字节），就是编码
- 把计算机才能看懂的内容（字节），解开成人类能看懂的字符，就是解码

关键记忆点就是：编码后计算机能看懂，解码后人类能看懂



## python 文件编码

python2 并没有规定 python 脚本文件的编码，默认按照 ascii 编码来读取 python 文件

如果我们没有任何定义，就会发现：

```
a = '中文'
```

就包含这么一行的 python 脚本是运行不起来的（python2）

```
SyntaxError: Non-ASCII character '\xe4' in file /Users/czp/workspace/projects/python-demo/p2.py on line 1, but no encoding declared
```

因此我们要让 python 解释器能够运行这么一个脚本，是需要定义脚本的编码的，首行添加：

```
# coding=utf-8
```

### # coding=utf-8 的作用

这个编码定义的作用就是告诉解释器：这个脚本文件本身是用 utf-8 编码的，你在把脚本文件读进来的时候（任何文件读出来都是一串字节），按照 utf-8 进行解码（把这串字节按照 utf-8 的方式解码成字符串）

作用也仅此而已，因此我们的脚本里只要包含非 ASCII 的字符，就需要添加这么一行。



## str 和 unicode

### str 是什么

python2 的 str 就是一串字节：也就是说相当于 java 里的 byte[]

当我们定义下面的字符串的时候：

```
a = 'abc'
b = '中文'
```

- a 其实就是 `abc` 的底层字节（`abc` 的 UTF-8 编码）
- b 也是 `中文` 的底层字节（`中文` 的 UTF-8 编码）

**之所以这里说的都是 UTF-8 编码，是因为这个 python 文件本身就是被 UTF-8 编码的，python 解释器读取到 `b = '中文'` 这一行的时候，读取到的 `中文` 这个内容本身就是被 UTF-8 编码的一串字节，直接就被赋值给了 b 这个变量。**

**如果我们在 python 文件开头定义的编码是 GBK，那么这里的 b 的内容就变成了 `中文` 的 GBK 编码（显然跟 UTF-8 编码的字节是不一样的）**

时刻谨记：str 是一串字节，当做 java 里的 bytes 来记忆

### unicode 是什么

unicode 是真正的字符串。python 里的 `a = u'中文'` 和 java 里的 `a = "中文"` 可以说是等价的

### 经常出现的编码异常是怎么产生的

#### python 的默认编码

python 的默认编码是 ascii，这是经常导致乱码的罪魁祸首

#### str 和 unicode 的相加操作

str 和 unicode 的相加操作最终结果是 unicode。那么是如何做到的呢？

```
a = u'中文'
b = '中文'
c = a + b    #  等价于  c = a + b.decode("ascii")
```

也就是说：python 会默认将 str 按照默认编码 ascii 解码为 unicode

异常原因是：`b.decode("ascii")` ，将 b 这么一大串字节按照 ascii 进行解码，结果 python 发现，这一串字节里有 大于 127 的内容，而 ascii 只有 0-127 对应的码表，所以这一大串字节是无法用 ascii 解码的，也就导致了异常

如果我们使用 `c = a + b.decode("latin-1")` 来解码的话，虽然会有乱码（一些奇怪的拉丁字符），但是不会导致异常，因为 latin-1 编码方式包含 0-255 所有的码表，任何字节序列都可以使用它来进行解码

#### 奇怪的 decode

实际上来说，我们只应该对 str 进行 decode，因为 unicode 已经是 decode 之后的结果了。

第一种情况：对包含中文的 str decode

```
a = '中文'
a.decode()
```

这里 `a.decode()` 等价于 `a.decode('ascii')`（系统默认编码 ascii），由于 `中文` 包含有 ascii 无法解析的字节（大于 127），因此导致解码异常

第二种情况：对一个包含中文的 unicode，又一次调用了 decode

```
a = u'中文'
a.decode()
```

这种错误的原因则是：只能对 str 进行 decode 操作，因此 python 解释器将 a 先转化成了 str 了。

也就是说上面的代码 `a.decode()` 等价于 `a.encode("ascii").decode("ascii")`

显然 `a.encode("ascii")` 这个调用中，a 是包含了中文的 unicode，将其使用 ascii 编码是不可能的：python发现对第一个字符 `中` 字编码时，在 ascii 的字符里根本找不到这个字，当然也就无从编起，从而报错。

##### 两种错误的区别

两种都是 decode 引起的错误，但是实际上来说，第一种情况引起的错误是解码错误（decode出错），而第二种情况引起的是编码错误（encode出错）

### print 做了什么

#### 输出 str

print 输出 str 的时候，什么都不做，就是老老实实的把 str 输出

要点：程序输出的当然是字节，str 本身就是一串字节，所以当然是按照原样输出

#### 输出 unicode

```
a = u'中文'
print a
```

当输出一个 unicode 的时候，print 其实是必须要将其转换成字节进行输出的（也就是 str）

这时候用到的编码是 `sys.stdout.encoding`，也就是要输出的终端的编码格式，在我的终端里，这个编码就是 UTF-8。

因此当 `print a` 的时候，实际上等价于 `print a.encode(sys.stdout.encoding)`，最终也就是将这个内容用终端相同的编码方式进行输出了



## 如何避免编解码异常

最简单的方案就是

```
import sys
reload(sys)
sys.setdefaultencoding("utf-8")
```

将默认编码修改为 utf-8



## 小结

- str 看做是一串字节：当我们在 UTF-8 编码的文件里写下 `a = '中文'` 时，a 就是这一串中文的 UTF-8 编码，其它编码同理。因此在不同编码的文件里写下 `a = '中文'`，**a 的实际内容（字节）其实是不同的**

- unicode 看做是一串字符：无论在何种编码里写下 `a = u'中文'`，**a 的实际内容都是一样的，都代表了这两个字符**
- 当我们读取和写入的时候，操作的都是字节，因此在这些场合，使用到的都是 str

